<h1 id="vibecoding-for-mathematics">Vibecoding for Mathematics</h1>
<p>Mathematics is an ancient and infinite game, with rules that appear
to be completely precise. The official rules of the game are the rules
of logical deduction: A therefore B, and hopefully never NOT A. The game
seems to have a completely specified reward function<a href="#fn1"
class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a> as
one example of a `win condition’, we can take the one achieved by
Perelman</p>
<p><em>Is every closed 3-manifold with trivial fundamental group is
homeomorphic to the standard 3-dimensional sphere, namely, the set of
real solutions to</em></p>
<p><span
class="math display"><em>x</em><sup>2</sup> + <em>y</em><sup>2</sup> + <em>z</em><sup>2</sup> + <em>t</em><sup>2</sup> = 1?</span></p>
<p><em>Give a proof or produce a counterexample</em>.</p>
<p>It is no surprise, then, that mathematics is a tempting challenge for
AI researchers, who have found great success by finding formulations of
aspects of human activity as games, and then by teaching computers to
play those particular games better than any existing human. Moreover,
while it is perfectly possible to do contemporary machine learning
research without knowing much about linear algebra, probability theory,
or gradient descent, the whole AI toolkit is, at its core, based on a
profound application of these ideas in a real-life context. It is
satisfying, for any human being, to try to go back to the very beginning
and to consume the body of the worm that once gave birth to you. Besides
that, real-world data is expensive, while mathematics is all in the
imagination, the purest high-status white-collar labor. What better test
case can there be for the great demonstration of the supremacy of a
universal solver of all intellectual tasks!</p>
<p>Thus, an obscure and well-funded war rages between the AI labs,
producing benchmarks and subsequently beating them. One well known
example work done by Epoch AI, where computers are asked to produce
numerical answers, with no justification required, to mathematical
questions that require a great deal of mathematical erudition to answer.
More excitingly, to shocking progress on the generation of formal proofs
for the problems of the 2024 and 2025 International Mathematical
Olympiad, a task that is widely regarded as requiring real creativity <a
href="#fn2" class="footnote-ref" id="fnref2"
role="doc-noteref"><sup>2</sup></a>. In turn these advances focused the
attention of the theoretical academic mathematical community on this
subject <a href="#fn3" class="footnote-ref" id="fnref3"
role="doc-noteref"><sup>3</sup></a>. The universality of this
attention-shift became clear to myself only recently, at a conference at
the Institute of Advanced Study, when I found out that a huge fraction
of my colleagues there were all paying OpenAI for their advanced
subscriber services in order to get access to their most powerful public
models, and regularly experimenting with them to see if they can indeed
assist with mathematical research.</p>
<p>Despite the truly impressive progress on these mathematical
benchmarks, the universal response from the myriad personal experiments
quietly being performed by research mathematicians seems to be that at
this very moment, the language models by themselves are only mildly
helpful for accelerating the research of existing human mathematicians,
and, at the very least, radically improved models or the development of
new tools and workflows is required. However, very few mathematicians
seem to doubt that these tools can be made to be helpful for real
research tasks in the near future (footnote 3), and of course, regarding
longer timeframes, the disagreement and uncertainty regarding how far
and in what manner the entire AI research agenda will progress is one of
the great debates of our historical moment.</p>
<p>This is not an essay on the future of mathematics, or on the politics
of skill, meaning, cultural power, knowledge, and human significance
that are implicit in current activity around Artificial Intelligence.
Instead, this is just my attempt to describe a system, which - Can be
(cheaply) built using existing or soon-to-be-existing capabilities, -
which dramatically changes the experience of human mathematicians doing
mathematics research, - In a manner that makes the human mathematicians
significantly more productive, and - Which the human mathematicians
enjoy and thus freely adopt the use of, and - Which feels like it is an
embodiment of the value systems of human mathematicians.</p>
The slogan I would like to propose is that we should aim to develop
tools that do
<div class="center-div">
<p><em>Vibecoding for Mathematics</em></p>
</div>
<p>although this slogan is slightly misleading, because the experience
of using such a system, unlike the subjective experience associated with
vibecoding, is likely to be very mindful.</p>
<p>Another way to summarize the idea is that what human mathematicians
might benefit from is access to a</p>
<div class="center-div">
<p><em>sentient, erudite, (slightly psychotic) calculator</em></p>
</div>
<p>in contrast to a model more focused on reducing mathematics to a vast
collaborative software-engineering project, which is how I would
describe the proposal entailed by the great deal of research activity
around the Lean Project. (links.)</p>
<p>Another, more humorous way of articulating this perspective is
that</p>
<div class="center-div">
<p><em>researchers interested in developing AI tools for mathematics
will have succeeded when they have a larger impact on actual mathematics
research than Mathematica has.</em><a href="#fn4" class="footnote-ref"
id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
</div>
<p>I’ll aim to describe the tool by describing a workflow that I
experimented with during the aforementioned conference, which led me to
change my beliefs, for the first time, - about some mathematical notions
that came naturally out of my own research, - regarding a question that
I genuinely wanted to know the answer to for a paper I was writing, -
due to a collaboration with an AI. The workflow experiment arose after
feeling inspired by a comment of Daniel Zheng of Google DeepMind, who
highlighted that despite the models’ many current challenges with
mathematical reasoning, the models are excellent coding assistants.</p>
<p>The mathematical question took the following form. There is a notion
of a “convex function” (picture) Which has the essential property that
when restricted to any real line segment <span
class="math display"><em>I</em></span>, it takes its maximum value at
one of the boundary points of the line segment <span
class="math display"><em>I</em></span>. There is an analog of this
notion where real numbers are replaced by complex numbers, called
J-convexity: the essential property of <span
class="math display"><em>J</em></span>-convex functions is that when
they are restricted to a complex line <span
class="math display"><em>Σ</em></span>, they take their maximum values
at the boundary <span class="math display">∂<em>Σ</em></span> of <span
class="math display"><em>Σ</em></span>. (As such, convex functions are
<span class="math display"><em>J</em></span>-convex, but not the other
way around.) Because symplectic geometry, my field of specialization,
relies heavily on a nonlinear version of complex analysis, <span
class="math display"><em>J</em></span>-convex functions are an essential
tool in the subject, because this convexity properties lets you control
where the complex lines can go.</p>
<p>Now, one of my current research projects is focused on finding
analogs of phenomena, and as such I have developed a hierarchy of useful
notions of “quaternionically convex functions”. In this hierarchy, the
stronger notions of convexity imply the weaker notions, I had found an
example that showed that the weakest notion did not imply the second
weakest notion, and I believed that the remaining notions were all
distinct as well, i.e. there were examples showing that one could
satisfy the convexity property lying lower on the hierarchy without
satisfying one the lying higher up. The following LLM-based workflow
changed my opinion on this matter – some of the weaker notions are
certainly equivalent to the apparently stronger notions, although I
currently do not know a proof of this fact. The expectation that an LLM
should also be able to find a proof of this empirically discovered
result is for me a paradigmatic example of what we should expect LLMs to
be able to do in the near future.</p>
<p>Here was the workflow:</p>
<pre><code>1.  Write up a short document in LaTeX, defining the relevant notions and providing some context, in a manner that one might do for a human collaborator, and then feeding this document to an LLM as context.
2.  Test the LLM through conversation regarding its knowledge of the prerequisite concepts (in my case, quaternions, differential forms, J-convexity), and then on its basic understanding of the new mathematical concepts defined in the document.
3.  Ask the LLM to prove some basic results which you know are true about the relevant notions, and inspect its arguments for `understanding’. Try to `clarify its understanding’ when there are errors. Also ask it to prove some false claims, read what happens, and offer similar clarifications.
4.  Ask the LLM to investigate a `nontrivial’ question. If it makes a serious claim (i.e. here is a counterexample), follow the maxim that has been widely understood by vibecoding practitioners: Force the AI to write tests.
    a)  Tests can be numerical, i.e. ``show me that you can write a numerical test to check if a given function is J-convex’’.
    b)  Tests can also be algebraic, i.e. verifying that some claimed algebraic identity holds. I found that the current LLMs are peculiarly bad at writing such tests, and I’ll expand on this below.
    c)  At some point, at the current stage of AI capabilities, one is likely to notice that the computer is providing truly nonsensical proofs using cool, high-concept ideas like symmetry which manifestly use none of the actual hypotheses assumed in the paper. Pointing out such errors to the LLM leads it to become tremendously confused. After such an error it is best to opt for a different strategy, as it’s unlikely that the LLM will be able to truly `overcome its own confusion’.
5.  A productive strategy is to ask the AI to help you write code for experiments which test hypotheses. This may be much faster than writing experiments code on one’s own – learning libraries can take forever, and the `erudition’ of LLMs can save the time it might take to derive, in a standard manner, formulae which make explicit some statements about more abstract mathematical objects (e.g. differential forms, cohomology groups).
6.  Given experimental outcomes, one can always ask the LLM about the meaning of the experimental outcomes. The LLM might in fact notice that a `counterexample’ is not a counterexample, due to a numerical error in the code! Or might be able to provide a proof of a lemma. Or you might be able to produce a proof of a lemma, once you are confident that the lemma is, in fact, true. 
7.  Throughout this process, one can run `human-in-the-loop’ cycles, and based on the numerical or symbolic experiments that the AI has assisted with, try to investigate newly hypotheses via the more standard process of human research.</code></pre>
<p>The document describing the problem setup is here. After the
experiments above, I now believe that the converse to Lemma XX holds,
which is real progress on a tiny piece of my research program. Links to
my conversations with ChatGPT can be found here and here; the generated
code can be found in these conversations, and the final code that
resulted is here. In the figures below, I have highlighted instances of
occurrences of the moments in the workflow described above.</p>
<p>There are also some obvious basic human-interface challenges
highlighted in the workflow described above which I imagine can be
overcome with a rather minimal amount of work. 1. Panes, “please fix the
error”, and other vibecoding tropes. The experience of using a modern
vibecoding tool like Cursor (link) is that of hilarious and
incomprehensible speed. You ask the computer to make you an app, and it
works — and then when it doesn’t work, you barely think, you just tell
the computer to FIX IT, and it gets straight back to work for you! It is
simultaneously exhilirating and mind-numbing to watch the computer go.
Much of this speed is, of course, a satisfying illusion, due to the many
bugs that vibe coding can introduce. However, there is no doubt that AI
models are genuinely helpful coding assistants. The vibecoding community
has developed many basic tooling insights around these capabilities,
i.e. chaining models together to tell other models to try to fix errors
as they pop up, which helps to create a smooth and satisfying
experience. These ideas can and should be adapted to the setting of
mathematics research.</p>
<pre><code>    For example, it would be a huge improvement on the workflow described above to

        - have a multi-pane setup, just as in cursor [figure], where one pane is a conversation with an LLM, and another is a series of code-windows into python or Mathematica or sage, in which the language model writes numerical code or symbolic tests for justifying its claims, and 

        - to have some basic automation around the use of this tool, i.e. to easily move code chunks between panes, and to be able to ask the LLM to ‘fix it’ repeatedly just as one does in a vibecoding setup. 

    In practice, having to do either of the above by hand repeatedly, dramatically decreased the value of the AI capabilities offered by current models for my research. I spent a few hours trying to vibecode a setup implementing the above capabilities, and unfortunately, perhaps due to my lack of expertise, I did not succeed immediately. However, a basic demo seems straightforward to implement.

2.  Language models are bad at writing code for symbolic programming languages like Mathematica or Sage. Math programming is more mindful than software engineering, and math-research tool systems should keep that in mind.
    This was a consistent issue in the experiment above. There is a tremendous amount of numerical code in python available on the internet. As such, language models are pretty good at writing numerical python code involving matrix manipulations — which is why they were able to write test the converse to Lemma XX. In contrast, their efforts to produce correct symbolic claims of statements beyond some level of complexity were rather abysmal, as were their abilities to generate code that improved on or verified their symbolic claims.

    If you look through the chat, you will see that even in the case of numerical experimentation, I had to carefully inspect each line of the written code in order to get the model to be correct, and to argue with the model, through some mathematical reasoning, in order to eventually get it to fix some obvious mathematical bugs. This contrasts with the goal of the vibecoding experience, in which one tries to `shut off one’s brain’ — in mathematics, one cannot really do this without a formal language verifying various intermediate assertions. As explained in the second part of the essay, it is essential for human practice to not require that all mathematical research is done in the setting of a single `formally verified library of mathematics’, as projects like Lean implicitly suggest one should— mathematics is too dependent on experiment, and on `low-depth’ symbolic statements, to make the required overhead worthwhile for some of the goals that human mathematicians have. Beyond that, mathematicians value the mindful aspect of the subject, and tools which use AI coding assistants as part of a mathematical workflow should be adapted to helping the human mathematician gain a rapid but detailed understanding of the relatively short code snippets that might be generated by such an AI. 

    Going beyond numerical coding, there is very little symbolic code on the internet, and so publicly available language models, at the time of the above experiment (May 2025) were completely incapable of doing something as simple as writing code to verify interesting quaternion matrix identities for which I could give careful proofs of by hand. To be clear, the motivation here is that — LLMs often produce elaborate sequences of symbolic manipulations in order to justify their assertions, and then make subtle mistakes in their reasoning. As such, just as in vibecoding, one should have them write tests that their symbolic assertions are correct, and then verify these `shallow’ symbolic assertions with a verifier. Such a workflow would implement this idea of a `sentient calculator’ alluded to in the introduction, and would fit completely naturally into human mathematical research processes. Why are we, in the 21st century, still doing confusing tensor calculations on paper when doing differential geometry? The computer knows all of these ideas — they are just a bunch of elementary manipulations with matrices and indices! Any IMO gold medalist, and certainly the computer, is better at such computations than I might be. In a just world, the computer should compile the ideas into code, and then test the code, and do the calculations for me. 

    Unfortunately, the ability for models to produce such tests in symbolic languages correctly is currently below the level required to make this capability feasible. Or, at the very least, some clever prompt engineering and workflow design is required, which I do not currently have on hand.

    This phenomenon is completely shocking to me — these are statements that, if I encoded them into Mathematica myself, the system would deterministically verify instantly! It is also eerie, as a mathematician, to look at some Sage code suggesting that some quaternion matrix identity doesn’t work, where one has a very careful human proof that it does. The bugs that AI can introduce are particularly vexing, and it is essential to optimize coding models on this slightly peculiar class of coding tasks in order to give massive value to human mathematics research projects. This is an area where hobbyist machine learning researchers, any AI company, or even a mathematician who decides to get into some ML research, can likely make a significant contribution.
3.  Integration with formal theorem provers.
    At this point, there exist AI systems that can produce human-readable solutions to IMO problems [links]. IMO problems are certainly at the level of the tasks that I want solved on a day to day basis in my research, and I doubt that the converse to Lemma XX above is any harder than a difficult IMO problem. Hopefully, the workflow above illustrates how problems motivated by high-level mathematics can often be boiled down to little lemmas that are no more complex than the kinds of problems that we believe AI systems should at this point be able to systematically solve. 

    Thus, the question is — how do we make these new tools useful? Part of the problem is access to the models themselves, but due to the exponential decreases in the costs of ML systems, one imagines that these will be widely available in the next few years. Beyond that, open source models do not do particularly badly on the IMO [link]. Thus, it is a problem of interface design and integration. One would like, in a single tool, in flexibly switch model providers, to easily switch between different verification modalities (numerical tests, symbolic tests, tests in a formal language like lean), in the process of one’s investigations. This is a problem that involves a mixture of ML model engineering and some HCI research.
4.  Conjoining coding, theorem-proving, and paper writing.
    As detailed in the second half of this essay, mathematical research involves different kinds of work, all of which can be assisted by artificial intelligence. Transferring data between tools which are not designed for integration can be a hassle, and when one is competing with the fluidity of manipulations on pen and paper — in which all `data transfer’ is instant, because most things are held in the user’s head — the interface presented has to be made quite smooth in order for a human to enjoy using it. The final products of mathematical research — papers — bubble out of agglomerations of these various kinds of work, most of which are unfortunately omitted in the final product (although the omissions may help readability). One could imagine a system that is something like an extension of the ideas around literate programming [links] in which one accumulates mathematical experiments, symbolic claims, little lemmas, carefully formalized definitions, into an elaborate hierarchical digital document, until as a final product, an easily navigable hierarchy of narrative, computer experiment, precise definitions and claims, human-readable proofs, and machine-verified proofs, is presented to the reader. This might lead to a form of mathematical production which genuinely improves on the current situation, which most practitioners find dissatisfying, but have trouble improving on. Writing papers is hard enough for human beings — but perhaps, with AI assistance, the papers we might write could fulfill all the goals that current papers achieve, and then some goals (partial formulation, examples, etc.) that we all wish were more widely available! The project of inventing the mathematics paper of the future [link] is a fascinating experiment in the creation of new human culture. </code></pre>
<p>I hope that these desiderata are helpful guidelines for researchers
interested in this problem. Personally, a tool that successfully
addressed even a few of the points above would become a daily assistant
for me in my research. I feel fairly confident that the same would be
true for a large fraction of working mathematicians.</p>
<p>There is question about the best institutional format for making
progress on the problem. One can imagine the open-source AI research
community experimenting effectively with this problem, and perhaps an
open-source project would be the ideal institutional format for the
development of a tool that a large fraction of mathematicians end up
using. On the other hand, there is no doubt that private companies can
develop tools that have a similar positive impact without many negative
social costs – again, there is the example of Wolram’s Mathematica,
which gave us the famous notebook interface that is now the mainstay of
machine learning research design ecosystems.</p>
<p>Permanently changing the ways of working of the global mathematical
community in a way that is generally agreed upon to be helpful would be
a significant and widely celebrated achievement. I hope that this is a
compelling motivator for AI researchers, designers, and computer
hobbyists to work with mathematicians on the design of such tools.</p>
<p>—–</p>
<p>There are some essential features of the workflow articulated above
that exemplify broader principles which assistants for mathematical work
might embody. In the rest of this essay, I want to highlight some
essential mathematical values which any toolmaker should keep in mind
when working on their design. These are not widely understood outside of
the math world, but I think they are essential to understand the problem
at hand.</p>
<pre><code>1.  Mathematicians spend much of their time playing with mathematical objects.</code></pre>
<p>Often, one might think of mathematicians as spending their time
verifying the correctness of abstruse sequences of logical statements,
or alternatively, imbibing massive quantities of caffeine and generating
the equally abstruse sequences of logical statements colloquially known
as “proofs” ex nihilo. While this does happen, this mischaracterizes
most of what the actual activity consists of. Fairly little time is
usually spent line-checking a given proof, because line-checking is
actually relatively unreliable: it is time consuming and often
error-prone for humans.</p>
<p>Instead, mathematical research often proceeds by the free play
through calculation and experiment with mathematical phenomena in a
manner that is structured and motivated by meta-mathematical principles,
i.e. informal structures which are observed in the structure of the web
of mathematical proofs themselves.</p>
<p>To explain this via example, we can go back to the problem in the
very beginning of the essay: the Poincare conjecture. An essential
contribution of Perelman to his proof of the Poincare conjecture was the
introduction of
<code>entropy-type estimates’ for the Ricci flow. Ricci flow is a flow on geometric spaces that is supposed to</code>smooth
them out’; the idea is that if you run the Ricci flow on something that
has trivial fundamental group, then hopefully one can prove that the
Ricci flow smooths out the geometry until the final geometry is that of
an actual 3-dimensional sphere, and so the original space must have been
topologically a 3-dimensional sphere to begin with. [Ricci flow figure.]
Up to extremely interesting technicalities, this turns out to work, but
the proof is difficult because the Ricci flow is a nonlinear equation,
and so one needs ways of controlling its long-time behavior to show that
no particularly bad behavior occurs that messes up the proof. In order
to find the a-priori estimates which control the long-time behavior of
the Ricci flow, the meta-mathematical principle that seems to have been
followed by Perelman is that: the diffusion of heat is underlaid by a
probabilistic phenomenon (Brownian motion), and so is controlled by
quantities related to the probability distribution of particles. The
most important such quantity is the entropy. The fact that entropy
decreases under heat flow was known to Gibbs, but only fully exploited
by researchers in optimal transport in the late 90s and early 2000s.
Perelman’s insight followed the (previously known) analogy that Ricci
flow is like the heat flow, but instead of being a flow of probability
distributions, it is a flow of metrics on manifolds (or, to make the
analogy more precise, for probability distributions on an unspecified
metric space, i.e. a flow through the space of metric-measure spaces) –
and as such, should be similarly controlled by an appropriate
entropy-type quantity. [Entropy. Perelman Entropy.]</p>
<p>Thus, a researcher may start with an imprecise but highly structured
analogical framework which synthesizes a large collection of
mathematical intuitions and phenomena into one supra-formal gestalt, and
then, guided by this gestalt, experiment with mathematical objects. If I
write down this kind of entropy-like quantity, does the mathematical
meta-pattern I am exploring allow me to produce the desired inequalities
which seem to get me closer to predicting the long-time behavior of the
Ricci flow? This involves play: experimenting with formulae,
symbolically describing relations between various abstract geometric
objects, exploring phenomena (in simple examples which can be
calculated), until one develops enough intuition to finally write down a
`magic’ formula which somehow, via a comparatively short sequence of
logical steps, ends up controlling some potentially chaotic or
unknowable nonlinear object which is the focus of one’s interest (for
the Poincare conjecture, this is the Ricci flow).</p>
<p>Thus the proof is only the final outcome of a rich and intuitive,
formal-and-informal process, and much of what mathematicians discuss and
aim to communicate is the mental and experiential tooling needed to
navigate this process. The communicated proof serves, first, as a
demonstration that the process was not `faulty’, and second, as a spare
collection of signposts for those interested in following along the
researcher’s path through the mathematical abyss.</p>
<p>I would like to argue that the tooling that mathematicians are
actually most interested in is tooling that vividly accelerates the
experimental process indicated above.</p>
<p>The experimental process might involve a fluid interplay of: rather
abstract symbolic calculations in a symbolic language designed on the
fly for the problem at hand; numerical experiments or visualization
exercises which give confidence to the researcher that certain claims
are true, which help the formulation of definitions or key lemmata;
short, lightweight nearly-formal proofs of `little lemmas’ which are the
keys to make some big argument go, and which articulate small and
helpful truths about the world; and an architectural process via which
definitions and theorem statements are designed so that one can see, in
one mental sweep, the structure of the entire argument, in order to make
it possible to be confident that the whole argument, with its zillions
of moving parts, is in fact perfectly correct because it is modular,
elegant, clean, and interpretable. <a href="#fn5" class="footnote-ref"
id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<pre><code>2.  Mathematicians are often concerned with finding and articulating the right concepts, statements, definitions, and beliefs, rather than with the correctness of any particular claim.</code></pre>
<p>This assertion may come as a surprise to non-mathematicians: after
all, aren’t we trying to prove Famous Conjectures? Indeed, we are — but
the solution of conjectures is (in my view, which I do not think is
wholly controversial) a way of demonstrating the power of one’s ideas,
and of keeping an
<code>objective’ measure of progress.  The conceptual artifacts that are most valued are really those that empower the synthetic process-cycle of experiment, conjecture, and proof. An isolated claim, even of an</code>important’
statement, is far less helpful for the acceleration of the process-cycle
than the wealth of intuitions, conceptual artifacts,
<code>tools’, and</code>objects’ produced as a byproduct of the process.
Of course, there are certain statements that are highly prized — think,
for example, of the Riemann hypothesis — because it is known that many
different
<code>interesting’ claims follow from a single such statement. Even in those cases, however, the hope is always that the proof of such a prize statement will lead to new structures that accelerate the process-cycle in many new, unexpected settings. For example, one hopes that the Riemann hypothesis is proven by the development of appropriate cohomology theory associated to systems of Diophantine equations, just as Riemann hypothesis</code>for
finite fields’ (link) was proven by the creation of the etale cohomology
theory. The reason for such a desire is that one is really interested in
all phenomena, which are usually interrelated, and one hopes that the
tool used to solve a famous problem clarifies our understanding of all
related phenomena — because usually, it is hard to prove something hard
without a new idea. Thus, for example, etale cohomology revolutionized
our understanding of many other questions about the structure of the
solutions sets to of systems of polynomial equations over finite fields,
even having a significant impact on the representation theory of finite
groups. A <code>direct’ or</code>elementary’ proof of the Riemann
hypothesis, which can be stated as some odd fact in complex analysis,
via some clever contour integral manipulations, would be deeply
fascinating, but there is a chance (!) that it might not lead to much
more clarity on any of the zillions of other questions we have about
number theory.</p>
<p>As such, without integration into the process-cycle of mathematical
<code>understanding’, even a perfect oracle which can produce elaborate non-conceptual but formally correct proofs of arbitrary correct mathematical claims would not obviously</code>end’
human mathematical practice. Indeed, without a conceptual toolkit, would
be difficult even to
<code>ask the right questions’ to the oracle. We will soon be able to test this claim directly: a weak version of such an oracle is now available in the example of the IMO solvers produced by Deepmind; yet, even if this solver was released tomorrow for free use by the mathematical community [^5], without a lot of thought given to human-computer-interface design and to methodology, this tool would be much less useful than a general IMO-level undergraduate research assistant to most human researchers. The development of tools around</code>proof
interpretability’,
<code>literate proof-writing’, are plausibly just as important as research problems in</code>AI
for mathematics’ as the improv rement of the capabilities of underlying
`formal proof oracles’ themselves.</p>
<p>The benchmark of `does this tool accelerate my research as much as a
very bright undergraduate would’ is being carefully tracked by the
entire mathematics community, and success on this benchmark cannot be
faked or questioned, in contrast to many other possible benchmarks
trying to evaluate the success of AI at mathematical reasoning. We turn
to this point next, in a slightly circuitous manner.</p>
<pre><code>3.  An essential part of the skill of a mathematician is not erudition or formal symbolic trickery, but is the ability to extract the little piece of elementary mathematics that underpins much more complex mathematical phenomena, and then by understanding/solving the elementary problem (or a sequence of such), radically changing the scope of accessible statements and claims. </code></pre>
<p>As an example, one can take `homological algebra’, the formal
mathematical content of which boils down to a collection of definitions
of almost comical formality and generality, together with a large
collection of elementary arguments in the setting of these definitions.
Many of the underlying arguments are actually simple statements about
the geometry of simplicies (high-dimensional triangles), the essence of
which can be explained to a bright high-school student. (This is, for
example, how I tend to think about the bar/cobar resolutions.) It is a
famous exercise by David Lang that the fastest way to learn homological
algebra, one should simply buy a textbook and prove all the theorems
without reading any of the proofs, and he wrote a textbook with this
methodology in mind. (Link.)</p>
<p>The value of homological algebra is that, in a very general manner,
it allows a researcher to `soften up’ many different mathematical
objects (whether of algebraic, geometric, or computational nature — what
is the difference?) of much greater complexity than a triangle, and
reason about them in a manner that engages an impressionistic collection
of intuitions developed from the study of topology. It is hard to pin
down what topology or homotopy theory are really about; perhaps the best
expression of the topological way of thinking (footnote: it is worth
perusing Grothendieck’s writing around this topic: link) accessible
without any technical training is captured artistically Fomenko’s
etchings. (Link) It is not possible to summarize the significance of the
effect of the universal application of these utterly elementary claims
about high-dimensional triangles on the structure of current
mathematical practice.</p>
<p>The most important such constellations of elementary statements are
repackaged, almost like in software engineering, into `machines’ — for
homological algebra, this ends up leading to fancy ideas like operads,
infinity-category theory, and homotopy theory. These high-concept,
high-status repackagings are the focus of tremendous fascination
(footnote: and even sometimes idolatry) by mathematically interested
Internet-users, who can sometimes make the error of forgetting to engage
with the underlying elementary ideas (which can only be seen in the
structure of the proofs), thus limiting or slowing down their
mathematical development.</p>
<p>By using these repackagings of elementary arguments, one can quickly
leap from one logical statement down a wormhole to another one, thus
<code>gluing together’ a collection of</code>machines’ (just as in
software engineering, much of which consists of writing and organizing
glue-code for existing libraries) to produce an answer to a
<code>sophisticated’ mathematical statement. This kind of</code>gluing’
requires a lot of erudition and awareness of the literature, and this is
something that current machine-learning models excel at. Erudition,
however, is only one part of the skillset of a mathematician, and by far
not the highest-`status’ skill.</p>
<p>The Frontier-Math benchmarks, designed by Epoch AI and paid for by
OpenAI (footnote: see these links for the relevant funding controversy,
which may or may not be of any importance depending on your beliefs
about the practices of AI research teams in the AI labs), are a
collection of questions which ask for an elementary numerical answer to
a sophisticated mathematical statement. The recent success of LLM-based
models on these benchmarks is responsible for part of the refocusing of
the attention of the mathematics community on progress in artificial
intelligence. In my estimation, there is a widely-shared sense that the
models, because they have
<code>read all existing literature’, are reasonably capable of gluing together such mathematical machines in order to produce the resulting numerical answers. Indeed, the models can be thought of as being impressive in their erudition! Yet, it seems possible that models might succeed in beating these “significant” benchmarks without having any significant effect on mathematical practice or research output. There is certainly some collection of interesting statements which should be accessible through a more systematic literature search, but there is an implicit belief that only a somewhat limited range of statements can be understood by</code>straightforwardly
gluing together existing tools’. The straightforward gluing is
considered to be trivial, even if it may be quite complex. This belief
plays into how mathematicians value problems which are accessible via
such methods. That is, in some sense, problems of this kind are problems
that we, as a species, have `already solved’ — even though we may not
know it yet.</p>
<p>The problems and solutions that are most valued by the math community
are those which we do not know how to solve, and for which a solution
“requires” what might be agreed upon to be a “radically new idea”. The
value placed absolute groundbreaking novelty — a concept which is
elusive to even define ! — is at the heart of the mathematical value
system. Can you recognize a new, powerful idea, when you see it?
Mathematicians debate which results matter, whose work really gets at
the heart of what is going on, over beers after conferences, in between
gossiping about academic politics and complaining about life. The bar is
very high, and many impressive variations on existing ideas do not pass
the secret expectations held privately in the hearts of many
researchers.</p>
<p>One might think of a successful human mathematical researcher as
inhabiting the opaque and inarticulable boundary between erudite
mathematics and elementary mathematics. The former is accessible via LLM
based “contextual literature search”; the latter is accessible via
“search in the space of formal elementary statements”. AI assistants
have found success with each of these tasks. Experience has shown that
what is valued is (in some but not all cases) non-obvious relationships
between these two poles. Which elementary mathematical statements are
important? What high-concept structures and tools are worth regard? Can
a future AI system cross the gap between these two styles of thinking,
which seems so essential in human practice — or can one find an entirely
different path to doing important research, which is recognized as such
by the best human practitioners? This recognition test is hard to
formalize, but is highly robust, and it has proven its stability over
the past millennia of cross-cultural human mathematical practice. You
know that your math, or your tool, is good, when it becomes part of the
air that mathematicians breathe. The analogy between a mathematical
machine (like homological algebra) and a computer machine (like
Mathematica) can help to clarify what success really looks like.</p>
<pre><code>4.  Mathematical values center human understanding, and even human joy, as the purpose of the activity.</code></pre>
<p>The experience of undergraduates studying mathematics can feel like a
slog, or even like torture. Senior mathematicians can complain of
loneliness, intellectual exhaustion, and a lack of social or financial
reward. Researchers might be motivated by glory, vanity, spite, fame,
stubbornness, or obsession. Nonetheless, the operative principle that
keeps the practice going is having fun. People do mathematics because
mathematical thinking, when it is going well, is exhilarating. Von
Neumann, famously, was addicted to thinking, and this addiction is still
popular today. In a Russian fable from my childhood, the fastest horse,
one even faster than the Wind, is Thought.</p>
<p>This motivation impacts the value system. A good proof introduces new
ideas to you which make your mathematical life more fun. Maybe this is
because it is wild and colorful and surprising and shocking, or it is
because it gives you some techniques which let you avoid painful and
confusing case-work via the lemmas and concepts established in the
proof. Maybe it just shows you something you really didn’t know was out
there, which you can now enjoy musing about on your own. A bad proof, in
contrast, is painful to read, hard to check, and doesn’t help you in any
way besides maybe confirming that something that you thought was true is
in fact true — and one always remembers that human proofs, especially
fiddly ones, tend to have errors. That being said, a bad proof is at
least some pathway through the unknown, so often bad proofs come first.
On the other hand, bad proofs, or proofs of mathematical conjectures
which come “too early”, can harm mathematical progress, as (link) Bill
Thurston famously points out.</p>
<p>The centrality of fun to the mathematical value system is discussed
at length by Michael Harris (link). In some ways, it is almost
irresponsible how much fun some mathematicians seem to be having. (Is
that allowed? Shouldn’t they be doing something else?) One can imagine a
world in which doing mathematics is never fun, in part because it never
centers what humans experience as fun. Maybe that un-fun world consists
of mining long streams of uninterpretable computer-generated arguments
for insights. In such worlds, which humans might continue to do
mathematics, and what possibilities might be lost by the inability for
humans to motivate themselves to participate in this activity?</p>
<p>Part of the reason mathematicians leave human mathematics is because
other human mathematicians do not do their mathematics in a way that
makes it as fun for other humans to interact with as the other humans
might want it to be. What might mathematicians enjoy about doing
mathematics in an AI-assisted world in the next 5, 10, 50 years? There
is a question of why this ancient human practice has value to human
societies in a changing world. Nonetheless, if one wants to have any
continuity with the current form of practice that one calls
`mathematics’ as the world transitions to a world where artificial
intelligence is plentiful, it is essential to focus on this core
principle driving the human practice, and to understand how it informs
what the humans actually do. Beyond that, if you want to learn from the
humans and to have them adopt your methods, they will happily do it if
the experience of doing so makes them have fun.</p>
<pre><code>4.  Essential claims about high-level concepts can (often) be reduced to precise formal claims about symbolic manipulations and numerical phenomena, without requiring a massive supporting infrastructure of libraries and formal arguments.</code></pre>
<p>Software engineers are used to invoking massive libraries based on
millions of lines of code in order to do a basic task like drawing some
text on a screen. In mathematics, we often use theorems and definitions
that take several books to completely establish. The total length of
these supporting materials is far shorter than the typical number of
lines of code supporting almost any software engineering tasks —
although, if these materials (e.g. textbooks on functional analysis)
were to be expanded into a formal theorem proving language, they might
end up as large as some software libraries. [Footnote: One thing we may
find out in the next few years is how large this
<code>mathematical codebase’ might be. In some cases we already know; the number of lines of code needed to have computers make sense of the formal (recent) notion of a perfectoid space is much smaller than that needed to encode a very simple web browser. [link] ] However, in contrast to software engineering, while working on proofs involving fancy concepts, mathematicians are constantly going</code>down
to the bare metal’, i.e. to elementary symbol manipulations,
combinatorial arguments, and statements about functions and numbers.
This is in part because of point 3 above, and in part because of point
5: mathematics, seen as a software library, is far more optimized for
fun than software is, so it is designed to avoid all the boring (but
essential!) parts of engineering. If mathematics were a programming
language, then all types would be assumed to be auto-convertible in the
mind of the mathematical user, and all glue code would be imagined to be
automatically generated (because it is `trivial’, see 3 again).
Contemporary mathematical proof tries to occupy a productive place in
the ambiguous boundary between the logically formal but boring world of
software, and the fluid and imprecise world of the human intuition!</p>
<p>Because of this, by design, it is far easier project a mathematical
statement to something elementary than it is to project a line of
software to some flips of a transistor or some manipulations of numbers.
Indeed, mathematicians are expected to be able to do this as part of the
demonstration of the value of their work — what does your theorem really
prove, what does it mean concretely? (Math is not as abstract as people
may think!) Researchers prize the ability to rapidly navigate the
abstraction latter, to show that a theorem in e.g. geometric
representation theory, a particularly abstract corner of mathematics,
implies or is nearly equivalent to a shocking but complex combinatorial
statement. Speakers at conferences, as a rhetorical strategy, may
illustrate the ‘hard heart’ of a statement, and then subsequently to
show how the difficulties disappear via abstract conceptualization. If
you, as a researcher, cannot do this, then other mathematicians will
doubt that your mathematics is real, and you will be constantly forced
to prove that your mathematics does indeed imply real statements though
other means; this pressure is well-known to workers in particularly
abstract areas like homotopy theory, and the tension this gives rise to
can be healthy or unhealthy. A wonderful diagram illustrating the
implicit demand for projectability onto the real can be found in
Cherednick’s Double Affine Hecke Algebras. [Figure. Cherednik, in his
bible on the DAHA, argues that it is much easier to produce abstract
mathematics than to produce truly new concrete mathematics.]</p>
<p>Thus, by design, mathematicians can often utilize formal methods
involving a ``shallow’’ infrastructure in order to work with
mathematical notions which might require the equivalent of a massive
software stack in order to formalize in a formal language. In a sentence
or two, some sophisticated claim might boil down to a fact about
matrices. This is illustrated in the workflow I described above, where
various notions coming out of a fairly high-concept project related to
new Floer-theoretic invariants boiled down to some matrix identities,
which the computer could write code for. Someone from a software
engineering background, if given the prompt I gave to o4, might try to
embark on a long project to first develop a library formalizing
differential geometry. [Footnote. Indeed, at the IAS conference where I
tested this workflow, someone thought about doing just that.] But all
this infrastructure is, to first and to second order, irrelevant for the
statement at hand. This is a gap between what software engineers may
believe mathematical practice is about, and what mathematics in practice
actually is. Language models, having observed a wider range of human
text-based behaviors than any human can, know that better than most
humans do; if anything, they are too aggressive about the simplifying
assumptions they make when asked to boil a mathematical statement down
into something concretely testable.</p>
<p>Sometimes, mathematicians introduce hugely incomputable notions into
their arguments, i.e. uncomputable numbers (which are required for
limits to work the way we want them to, which in turn is quite useful
for doing mathematics that can then be turned into real concrete
algorithms) or the very infinite chain complexes computing the
aforementioned etale cohomology groups (which then turn out, in many
cases, to be easily computable through some abstract comparison theorem,
and then imply all kinds of empirically testable number-theoretic
claims, which may serve as particularly compelling `evidence’ that the
proofs about etale cohomology are correct — it is hard to <em>guess</em>
so many correct statements!). In all these cases, what is valued is the
eventual bottoming-out of these uncomputable notions into concrete
computational realities. Moreover, the experimental data coming in
(e.g. of computations of various abstruse quantities in homotopy theory)
heavily motivates the highly incomputable notions that end up being
defined and studied.</p>
<p>In order to keep the fluidity of mathematical practice, it is
important not to overburden tools for mathematical research with too
many of the infrastructural expectations of software development
practice. Doing so runs the risk of failing to support, or even harming,
certain valuable forms of human mathematical activity which can proceed
much faster than any completely systematic approach.</p>
<pre><code>5.  Human proofs and symbolic calculations are analogous to tests in software engineering. </code></pre>
<p>Any discussion of different concepts of proof probably must refer to
Lakatos’s [link]. This essay illustrates the essential role that
interpretation has in the notion of a proof. There is no doubt that a
large codebase can be formally verified by a codebase that is small
enough that we can have a great deal of confidence in the correctness of
the verifier. However, humans do not care about the formal correctness
of formal statements in a formal language; we care about what is true
about things that have a meaning to us. Thus, a fear that a
mathematician might have is that a massive project claiming to formally
prove something important in a formal language may instead formally
prove something else, because in the process of writing a long,
uninterpretable formal proof, can easily introduce errors of
interpretation.</p>
<p>This fear explains, in part, the value that mathematicians place on
good definitions over good theorems. When using a good definition, one
can clearly check that a claim is precise enough to be formalizable, and
this may translate into the ability to write corresponding formal
statements in a formally verified language, about which one is confident
in their interpretation. Only if one is completely confident in the
interpretation of the meaning of a statement in a formal language, can
one allow a machine to generate a massive, incomprehensible, formally
verified proof of this formal statement. Often, humans read one
another’s papers in a similar manner — one is advised, e.g. by on one’s
Ph.D. advisor, to read the statements of the main lemmas and theorems,
to make sure one knows precisely what they claim, and then to produce
the proofs on one’s own — because humans are not nearly as good at
writing readable or completely correct proofs as they are at writing
definitions and meaningful statements.</p>
<p>As such, one can think of a precisely stated lemma, and its short
proof, as similar to a test in the world of software engineering. One
can possibly disprove the lemma by producing a counterexample, possibly
using a numerical method; or, failing that, being able to produce a
proof of the lemma increases one’s confidence that the whole logical
edifice is correct. The way that mathematicians referee one another’s
papers bears much more resemblance to the process of running a paper’s
claims against a massive array of tests, just as in software
engineering, than it does to formally verifying all claims in a formal
language — although, of course, referees often verify the most essential
claims of the argument, line by line, to the best of their ability,
precisely because the claims are essential. This is part of the reason
for why humans break up their arguments into many clean lemmas — it
makes it easier for other researchers to run tests against their work,
and thus to have a much higher degree of trust in its correctness.</p>
<p>One can imagine using a formal proof system that can write formal
proofs of ‘little lemmas’ in an integrated manner with a human guided
research agenda — a human, navigating an area of mathematics, makes
lemmatizable claims, formalizes them in a formal language (possibly with
AI assistance), and then an uninterpretable formal proof might help the
human to change their confidence in what kinds of `nearby’ statements
are true or false. Better yet, an interpretable proof might change the
human’s whole perspective on the subject. An interpretable proof is a
test of the reader’s understanding of the situation; another reason for
why AI-based proof generators, to be truly useful, must be able to
sometimes produce human-interpretable arguments. (To see the difference
between a readable proof and an unreadable proof, compare the Google IMO
submission [link] with the Open AI one [link].)</p>
<p>There is not much of a gap between a small lemma and a claim about a
symbolic system, i.e. a symbolic manipulation. As explained in the
previous point, very `shallow’ symbolic assertions can be at the core of
very deep mathematics, or can test the correctness of propositions about
the latter. This is another point to keep in mind when thinking about
which AI capabilities might be most helpful for impacting mathematics
research that humans might value, and is part of what explains
Mathematica’s significant impact on research.</p>
<pre><code>6. Informal, symbolic `techniques’ endowed with a rich set of associations and intuitions can be just as important as formal proofs, and indeed can significantly outrank formal proofs in their mathematical importance.</code></pre>
<p>To see this point made most vividly, one can turn to the example of
the existence of the theoretical physics community. Mathematics used to
refer to a much larger tent: before some point around 1920-1950, there
was no distinction between theoretical physics and mathematics; Einstein
was a mathematician, and arguably, many machine learning learning
researchers would be mathematicians by the historical standard, although
they would hardly see themselves this way today. (There is an argument,
which I am sympathetic to, that the historical usage of the term is more
useful than the contemporary one, whatever the latter may be.) However,
the style of theoretical physics takes a different approach from the
style of pure mathematics, focusing much more on elaborate symbolic
calculational techniques, without requiring complete grounding in some
kind of system of putatively complete proof. This method is reminiscent
of the mathematics of the 19th century, and turns out (in part through
implicit support by the pure mathematics community, and by other
communities doing much more computational or even experimental
investigations) to give rise to very efficient ways of discovering new
mathematical truths. In part, it is important because the structure of
our understanding of current physical law still lies far outside the
realm of complete mathematical formalizability, even at the informal
level that human mathematicians expect; and in part, it is important
because this method has often led to revolutions in pure mathematics,
for example, in my field, symplectic geometry, with the initial
discovery and exploration of ``mirror symmetry’’. It turns out, through
experiment, that motivated symbolic manipulations coupled to grounded
computational experiments give theorem-proving a run for its money!</p>
<p>More shockingly yet, it is still possible to be something of a
<code>prophet’ in relatively recent mathematical practice. One vivid example of this kind of thing is Jack Morava’s work on chromatic homotopy theory, which used various highly symbolic associations between certain algebraic structures at different levels of mathematical abstraction to</code>predict’
a series of massive organizing principles for the structure of homotopy
theory, which were then later established by a large number of different
researchers, and have since become one of the basic touchstones of the
subject. Part of this
<code>ideology’ involves expanding one’s basic concept of the idea of a</code>number’
— in Morava’s world, there are extra
<code>prime numbers’ interpolating between each prime number and the</code>prime
at infinity’ — and consequently, it has taken a long time for this
nearly-ridiculous idea to diffuse to the rest of mathematics, and (in
accordance with the earlier points of this essay) the diffusion has only
occurred as the underlying tools have found
<code>real applications’ to the questions of interest to researchers in other areas. A particularly interesting question, I think is whether AI tools might help with</code>mathematical
prophecy’: whether there is a tool that could enable an unknown Morava
of the future to make ten equally-significant discoveries, though some
rapid iteration of symbolic and experimental mathematical methods.</p>
<p>In practice, a significant part of the actual work of mathematicians
can look something like doing theoretical physics-like ‘formal-informal’
calculations in various temporary made-up languages which are
tailor-built to investigate whatever phenomenon the mathematician is
trying to investigate. It is an essential design question of how to
support that kind of work with AI-based tools, and how to integrate that
kind of support with support for something closer to the
definition-theorem-proof style of mathematical exposition. Often, the
most influential mathematical work seems to straddle all the styles of
mathematical activity — the experimental, the symbolic-calculational,
and the proof-based approaches — and designing around this process is a
question which brings any designer into contact with a peculiar and
powerful part of the human psychological capacity.</p>
<hr />
<p>Tools embody values which change their users. A knife is elegant,
effective, dangerous, and portable. For a few people throughout history,
the mathematical tricks of modeling, symbolic manipulation, and a
certain blend of intuitive and systematic thinking, have had a similar
quality for their practitioners.</p>
<p>The best tools are as easy to use a a knife. A tool which embodied
the implicit values of the mathematical community would be easily picked
up by mathematicians, and then naturally integrated into their lives. It
might form a daily component of their work, and through this
integration, change both what is possible and what is considered
meaningful.</p>
<p>The tool builder has some responsibility for the impact that they
have on the world.</p>
<p>The approach towards toolbuilding described in this essay feels, to
me, like<br />
the highest-impact, most realistic, nearest-term way<br />
that AI can contribute to changing<br />
the practice of research mathematics at the very highest level,<br />
in a manner that actually furthers<br />
the intellectual goals of the few beings we know of<br />
who have demonstrated the skill of producing significant mathematical
advances, and who,<br />
at the moment,<br />
all happen still to be<br />
human beings.</p>
<p>P.S. I would be very happy to discuss new tools and new workflows
about vibecoding for mathematics with anyone who is interested. Please
feel free to contact me at my academic email if you wish to discuss!</p>
<section id="footnotes" class="footnotes footnotes-end-of-document"
role="doc-endnotes">
<hr />
<ol>
<li id="fn1"><p>The real history of the resolution of this particular
question highlights one way in which the reward function is a little bit
subtle: what is a proof, and what is `standard knowledge’?<a
href="#fnref1" class="footnote-back" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p>A significant amount of attention has gone to looking at
the <em>content</em> and style of the formal, i.e. Lean-language, proofs
produced by the IMO solver, which involve interesting moves like
inductions on the integer i=12.<a href="#fnref2" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>There is and has been an active debate about whether the
way that human mathematicians currently do research proves that they are
essentially Luddites. Prof. Doron Zeilberger’s works (link) and opinions
(link) are well worth perusing to see one human mathematician’s argument
for this perspective.<a href="#fnref3" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>(Footnote: This is a serious benchmark. Stephen Wolfram
once said in a lecture at NYU that I attended that he rates his impact
on the practice of mathematics as second only to Newton, who invented
Calculus. I personally think this is something of an exaggeration, but
the impact of symbolic algebra tools like Mathematica shouldn’t be
understated, in part because these tools have are daily tools in the the
work theoretical physicists, whose work has often been at the heart of
new mathematical discoveries.)]<a href="#fnref4" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
<li id="fn5"><p>This might be a point in which computers can
comparatively easily dominate human mathematicians by going around human
weaknesses: humans cannot verify large elaborate arguments without
introducing structures like
<code>high-level concepts’ which enhance interpretability. Perhaps one might imagine a</code>code-golf’
computer-produced Lean proof of the Poincare conjecture, which never
touches the Ricci flow, but is some elaborate combinatorial argument.
Many such arguments were in fact attempted by human mathematicians
before Perelman’s work, but none succeeded. It is interesting to
meditate on what value, if any, such an elaborate, difficult to
interpret, apparently a-conceptual proof of the Poincare conjecture
might have.<a href="#fnref5" class="footnote-back"
role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
